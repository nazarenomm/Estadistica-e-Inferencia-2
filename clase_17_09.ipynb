{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimensionalidad de un posterior es la cantidad de parametros, recordar que la posterior es una distribucion conjunta de los posteriors marginales.\n",
    "\n",
    "Cuidado con el lenguaje causal, que las variables esten correlacionadas no quiere decir que una cause la otra.\n",
    "\n",
    "El grafico de la posterior predictive es una gaussiana desde arriba. Por cada observacion estamos poniendo una gaussiana.\n",
    "\n",
    "Hay bicicletas alquiladas negativas. Para solucionar (?) esto aparecen los glm.\n",
    "\n",
    "La $\\Phi$ puede ser una distribucion que **no** sea de la familia exponencial.\n",
    "\n",
    "el exp en deterministic es para que $\\mu$ sea positivo.\n",
    "\n",
    "En una Negativa Binomial a medida que aumento mu aumenta la varianza, se ve en el grafico.\n",
    "\n",
    "La linea ya no es recta, eso pasa porque usamos una funcion de  enlace (o enlace inverso).\n",
    "\n",
    "A veces podemos cambiar alguna distribucion por una mas robusta, como pasar de una Normal a una T de Student.\n",
    "\n",
    "La T de student da regresiones mucho mas robustas, por que no se usan siempre?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estadistica_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
