{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de los bebes\n",
    "\n",
    "MutableData te ayuda para despues cambiar los valores de x. Le estamos diciendo al modelo que las x son variables y no constantes.\n",
    "\n",
    "Vemos como sigma aumenta con los meses, entonces así lo modelamos.\n",
    "\n",
    "Esto es un modelo distribucional, ya que los parametros estan modelados como lineales (?).\n",
    "\n",
    "cuando hacemos sample_posterior_predictive, uso los x observados. Si quiero generar obtener una prediccion para el mes 0.5 (2 semanas), como use MutableData, puedo decirle el x que quiero (o los x).\n",
    "\n",
    "### Regresión por cuantiles\n",
    "\n",
    "Para modelar cuantiles usamos AsymmetricLaplace, q es la paramterizacion para los cuantiles.  \n",
    "\n",
    "Si uso esta distribucion como likelihood estaria modelando el cuantil.\n",
    "\n",
    "Esta distribucion no explica los datos, es solo un truco estadistico.\n",
    "\n",
    "Recordar:  \n",
    "1) existen las regresiones por cuantiles\n",
    "2) No nocesariamente los datos siguen la distribucion usada\n",
    "\n",
    "En el ejemplo hay tres regresiones en una sola.\n",
    "\n",
    "Cada linea representa el cuantil respectivo.\n",
    "\n",
    "Despues se compara una regresion lineal simple con la regresion por cuantiles.  \n",
    "la linea punteada es la media, y los cuantiles podrian ser media +- constante*sigma.  \n",
    "Se ve que no son lo mismo, las lineas punteadas son paralelas y las solidas cambian.  \n",
    "Podria haber hecho que sigma sea variable (la modelo).\n",
    "\n",
    "### Regresión lineal jerárquica\n",
    "\n",
    "Para el grupo con 1 valor habria infinitas rectas que pasen (para todos los grupos pasa esto, por ser un modelo Bayesiano). Esto se soluciona al hacer un modelo jerarquico.\n",
    "\n",
    "Muchas divergencias, incluso para target_accept altos (0.9999), tendremos que reparametrizar.\n",
    "\n",
    "B_offset seria una normal standard, lo que se hace es multiplicar beta_sigma por esta normal y luego despazar la normal resultante hacia beta_mu.\n",
    "\n",
    "Lo del log(beta_sigma) se hace con todas las distribuciones truncadas (con limites) ya que pymc por dentro la transforma para que no tenga limites.  \n",
    "Entonces usamos log(beta_sigma) para que se vea más exagerado.  \n",
    "\n",
    "Ver que muestree mejor usando la estrategia del offset, la cola del embudo es mas larga.  \n",
    "\n",
    "Lo de arriba es lo que ve el sampler, algo más fácil de muestrear. Lo de abajo es lo que vemos nosotros.\n",
    "\n",
    "### Regresión lineal múltiple\n",
    "\n",
    "Ya lo sabemos\n",
    "\n",
    "### Bambi\n",
    "\n",
    "Es una libreria escrita sobre pymc, se especializa en GLMs y algunas extensiones como modelos jerarquicos, splines (GAMs), GPs.\n",
    "\n",
    "Usa las formulas de Wilkinson (BUSCAR).\n",
    "\n",
    "No confundir los x.\n",
    "\n",
    "Se inventa los priors a partir de los datos.\n",
    "\n",
    "fit es parecido al sample, le puedo pasar los mismos argumentos.\n",
    "\n",
    "devuelve un InferencedData\n",
    "\n",
    "tengo metodos que simplifican los ploteos.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
